{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
      "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: tim.belden@enron.com\n",
      "Subject: \n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen (Non-Privileged).pst\n",
      "\n",
      "Here is our forecast\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tokenization, Stop-word and Punctuation Removal Functions\n",
    "Before proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "Nsamp = 1000 # number of samples to generate in each class - 'spam', 'not spam'\n",
    "maxtokens = 200 # the maximum number of tokens per document\n",
    "maxtokenlen = 100 # the maximum length of each token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use regular expressions to remove unnecessary characters\n",
    "\n",
    "Next, we define a function to remove punctuation marks and other nonword characters (using regular expressions) from the emails with the help of the ubiquitous python regex library. In the same step, we truncate all tokens to hyperparameter maxtokenlen defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(text):\n",
    "    # Remove file paths (e.g., \"O:\\CurveValidation\\Estate Reporting...\")\n",
    "    text = re.sub(r'[A-Za-z]:\\\\[^\\s]+', '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove common email headers (From, Sent, To, Subject, etc.)\n",
    "    text = re.sub(r'(From|Sent|To|Subject):.*?\\s', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove date and timestamp information (common patterns)\n",
    "    text = re.sub(r'\\b(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun)\\b,?\\s+\\d{1,2}\\s+\\w+\\s+\\d{4}', '', text)\n",
    "    text = re.sub(r'\\b\\d{1,2}:\\d{2}\\s?(?:AM|PM|am|pm)?\\b', '', text)\n",
    "\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # Remove multiple spaces and trim whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop-word removal\n",
    "\n",
    "Let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily-used list that will employ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/revanthv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')    \n",
    "print(stopwords) # see default stopwords\n",
    "\n",
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved message body from e-mails!\n"
     ]
    }
   ],
   "source": [
    "# Separate headers from the message bodies\n",
    "import email\n",
    "\n",
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        # Return a message object structure from a string\n",
    "        e = email.message_from_string(item)    \n",
    "        # get message body  \n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    print(\"Successfully retrieved message body from e-mails!\")\n",
    "    return messages\n",
    "\n",
    "bodies = extract_messages(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_length = 0\n",
    "for i in bodies:\n",
    "    mean_length+=len(i.split(' '))\n",
    "mean_length = mean_length//len(bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517401, 110175, 249307)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_email_bodies = []\n",
    "max = 0\n",
    "for i in bodies:\n",
    "    length=len(i.split(' '))\n",
    "    if length>max:\n",
    "      max = length\n",
    "    if length>=mean_length:\n",
    "        sample_email_bodies.append(i)\n",
    "len(bodies),len(sample_email_bodies),max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dave \\n\\nThe PPA schedule was pushed back two weeks.  I would like to keep our meeting \\nwith Skilling because I heard he was going to Africa for 3 weeks.\\n\\nLavo\\n---------------------- Forwarded by John J Lavorato/Corp/Enron on 06/12/2000 \\n09:47 AM ---------------------------\\n\\n\\nAndre Templ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of the type of things I continue to manage for Citizens.  \\nAt this point my role is customer service, making sure their questions and \\nconcerns are being addressed.  I work extensively with Patti Sullivan and \\nDarla Saucier to keep things on even keel.  I would like to stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark, FYI - In my estimation this business is no bigger than Mexico or the \\nToronto business ie) $25 to $30M in real value with reasonably high risk.  I \\nsee no value in having two different agendas being pushed in S. America.  I \\nalso believe that we could cut overhead and right size the org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have a Safe &amp; Happy Thanksgiving Everyone !!\\n\\n \\n\\nTHOU SHALT NOT SKIM FLAVOR FROM THE HOLIDAYS \\n\\nBy Craig Wilson, USA TODAY \\n\\nI hate this time of year. Not for its crass commercialism and forced \\nfrivolity, but because it's the season when the food police come out \\nwith their wagging fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jerry Scarbrough's True Orange\\nThe newsletter and fax/e-mail service for the True Texas Longhorn Faithful\\n\\nVolume 10, No. 21, August 28, 2000\\n\\nStronger Defense, Improved Punting, Explosive Offense Give Horns Chance to\\nStay in Top 10\\n\\nWith two-a-day workouts almost over and the opening ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             0\n",
       "0  Dave \\n\\nThe PPA schedule was pushed back two weeks.  I would like to keep our meeting \\nwith Skilling because I heard he was going to Africa for 3 weeks.\\n\\nLavo\\n---------------------- Forwarded by John J Lavorato/Corp/Enron on 06/12/2000 \\n09:47 AM ---------------------------\\n\\n\\nAndre Templ...\n",
       "1  This is an example of the type of things I continue to manage for Citizens.  \\nAt this point my role is customer service, making sure their questions and \\nconcerns are being addressed.  I work extensively with Patti Sullivan and \\nDarla Saucier to keep things on even keel.  I would like to stay...\n",
       "2  Mark, FYI - In my estimation this business is no bigger than Mexico or the \\nToronto business ie) $25 to $30M in real value with reasonably high risk.  I \\nsee no value in having two different agendas being pushed in S. America.  I \\nalso believe that we could cut overhead and right size the org...\n",
       "3  Have a Safe & Happy Thanksgiving Everyone !!\\n\\n \\n\\nTHOU SHALT NOT SKIM FLAVOR FROM THE HOLIDAYS \\n\\nBy Craig Wilson, USA TODAY \\n\\nI hate this time of year. Not for its crass commercialism and forced \\nfrivolity, but because it's the season when the food police come out \\nwith their wagging fi...\n",
       "4  Jerry Scarbrough's True Orange\\nThe newsletter and fax/e-mail service for the True Texas Longhorn Faithful\\n\\nVolume 10, No. 21, August 28, 2000\\n\\nStronger Defense, Improved Punting, Explosive Offense Give Horns Chance to\\nStay in Top 10\\n\\nWith two-a-day workouts almost over and the opening ga..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract random 10000 enron email bodies for building dataset\n",
    "import random\n",
    "bodies_df = pd.DataFrame(random.sample(sample_email_bodies, 10000))\n",
    "\n",
    "# expand default pandas display options to make emails more clearly visible when printed\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "\n",
    "bodies_df.head() # you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\n",
    "EnronEmails = bodies_df.iloc[:,0]\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(10)\n",
    "\n",
    "data = pd.DataFrame({\"Tokenized_text\": EnronEmails})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined data represented as numpy array is:\n",
      "(10, 1)\n",
      "Data represented as numpy array is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>Gerald: When I got your form I converted it to WordPerfect 9.0 and then did the revisions. Apparently when I converted it back to Word, it didn't \"take\". I was able to convert it to Plain Text which I am attaching to this message. At least you can read it. Please call with any questions Nemec, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>---------------------- Forwarded by Andrea Ring/HOU/ECT on 05/02/2001 PM --------------------------- Michele on 04/04/2001 Maria Teb Andrea cc: FW: weepy Choices &gt; &gt; At a fund-raising dinner for a school that serves learning-disabled &gt; children, the father of one of the school's students deliver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9644</th>\n",
       "      <td>GADSDEN RESEARCH SERVICES' FERCwatch Issued February 5, 2002 ELECTRIC / HYDRO Report: Southern California Edison Company, ER02-925-000 (01/31/02) -- Revision to Transmission Owner Tariff to reflect proposed changes to transmission revenue requirements and transmission rates applicable to wholesa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>strong! -----Original Message----- [mail Tuesday, May 29, 2001 Carson, Mike RE: attire Mike, If you have any trouble finding the restaurant, I've included directions below: To Chapel Hill from RDU Airport: Take I-40 West and proceed to exit 273 B which is highway 54 West. Proceed on 54 West whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>I am very interested in pursuing this and I believe Enron presents an ideal case study for the purposes you outlined. I am copying Christie Patrick on this message and asking her to coordinate this for us. Christie has worked on other case studies and will be very helpful in navigating Enron for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                   Tokenized_text\n",
       "7330  Gerald: When I got your form I converted it to WordPerfect 9.0 and then did the revisions. Apparently when I converted it back to Word, it didn't \"take\". I was able to convert it to Plain Text which I am attaching to this message. At least you can read it. Please call with any questions Nemec, G...\n",
       "1356  ---------------------- Forwarded by Andrea Ring/HOU/ECT on 05/02/2001 PM --------------------------- Michele on 04/04/2001 Maria Teb Andrea cc: FW: weepy Choices > > At a fund-raising dinner for a school that serves learning-disabled > children, the father of one of the school's students deliver...\n",
       "9644  GADSDEN RESEARCH SERVICES' FERCwatch Issued February 5, 2002 ELECTRIC / HYDRO Report: Southern California Edison Company, ER02-925-000 (01/31/02) -- Revision to Transmission Owner Tariff to reflect proposed changes to transmission revenue requirements and transmission rates applicable to wholesa...\n",
       "1585  strong! -----Original Message----- [mail Tuesday, May 29, 2001 Carson, Mike RE: attire Mike, If you have any trouble finding the restaurant, I've included directions below: To Chapel Hill from RDU Airport: Take I-40 West and proceed to exit 273 B which is highway 54 West. Proceed on 54 West whic...\n",
       "8775  I am very interested in pursuing this and I believe Enron presents an ideal case study for the purposes you outlined. I am copying Christie Patrick on this message and asking her to coordinate this for us. Christie has worked on other case studies and will be very helpful in navigating Enron for..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of combined data represented as numpy array is:\")\n",
    "print(data.shape)\n",
    "print(\"Data represented as numpy array is:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def summarize_email_thread(thread_text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + thread_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    inputs = inputs.to(device)\n",
    "    summary_ids = model.generate(inputs, max_length=200, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "data['summary'] = data['Tokenized_text'].apply(summarize_email_thread)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenized_text    Thanks looks good. I guess I just have a chip on my shoulder these days about being relegated to the world of details! -----Original Message----- Fossum, Drew Tuesday, September 25, 2001 Corman, Shelley FW: Settlement Offer Here's the latest draft--this is on the way over to staff right now. I'l...\n",
       "summary                                                        Summarize: Thanks looks good. I guess I just have a chip on my shoulder these days about being relegated to the world of details! Here's the latest draft--this is on the way over to staff right now. I'll make sure all future settlement stuff goes to you.\n",
       "Name: 1339, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Tokenized_text','summary']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/revanthv/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable for MPS fallback\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Add padding token to tokenizer if it does not exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer)) \n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized_text</th>\n",
       "      <th>llama_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>Please forward to James Scribner. He will call with his e:mail address. = =20 ---------------------- Forwarded by Sally Beck/HOU/ECT on 01/25/2000 = AM=20 --------------------------- =20 =09Enron North America Corp. =09 =09 Rick Causey @ ENRON 01/17/2000 =09 Sent by: Enron All Enron Worldwide cc...</td>\n",
       "      <td>summarize: Please forward to James Scribner. He will call with his e:mail address. = =20 ---------------------- Forwarded by Sally Beck/HOU/ECT on 01/25/2000 = AM=20 --------------------------- =20 =09Enron North America Corp. =09 =09 Rick Causey @ ENRON 01/17/2000 =09 Sent by: Enron All Enron W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>Uh, YEAH! There's a WHOLE BUNCH of them! Single ones, squishy ones, firm ones...wanna feel 'em? =o) HA HA HA!!! -----Original Message----- Symes, Kate Wednesday, May 02, 2001 Rodriguez, Grace Re: EWWW TOMATOES! You have beef-cakes up there? Are they single? Grace on 05/02/2001 CDT Lysa Tom Rober...</td>\n",
       "      <td>summarize: Uh, YEAH! There's a WHOLE BUNCH of them! Single ones, squishy ones, firm ones...wanna feel 'em? =o) HA HA HA!!! -----Original Message----- Symes, Kate Wednesday, May 02, 2001 Rodriguez, Grace Re: EWWW TOMATOES! You have beef-cakes up there? Are they single? Grace on 05/02/2001 CDT Lys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>Thanks. -----Original Message----- Novosel, Sarah Thursday, October 25, 2001 Shapiro, Richard; Steffes, James D. Cc: Robertson, Linda FW: November 2 Seattle Conference I sent to Kevin the names forwarded to us from Paul for possible panelists from Western governors' offices for FERC's November 2...</td>\n",
       "      <td>summarize: Thanks. -----Original Message----- Novosel, Sarah Thursday, October 25, 2001 Shapiro, Richard; Steffes, James D. Cc: Robertson, Linda FW: November 2 Seattle Conference I sent to Kevin the names forwarded to us from Paul for possible panelists from Western governors' offices for FERC's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>-----Original Message----- Stein, Neil [mailMonday, September 24, 2001 undisclosed-recipients CSFB Independent Power Weekly--Issue #44 &lt;&lt;IPW092401.pdf&gt;&gt; Good Morning, Attached, please find the latest issue of our Independent Power Weekly. Also note that there is a replay available of our confere...</td>\n",
       "      <td>summarize: -----Original Message----- Stein, Neil [mailMonday, September 24, 2001 undisclosed-recipients CSFB Independent Power Weekly--Issue #44 &lt;&lt;IPW092401.pdf&gt;&gt; Good Morning, Attached, please find the latest issue of our Independent Power Weekly. Also note that there is a replay available of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>John or Marissa, please call me at your convenience on my cell, 713 304 8716. Thanks, Kay \"Keffer, John\" on 03/23/2001 :47 PM cc: \"Reuter, Marisa\" RE: ENA/Blue Dog: Revised Letter Agreement I failed to include the conference call information, which is noted below: number: 877-232-0064 pin: 25581...</td>\n",
       "      <td>summarize: John or Marissa, please call me at your convenience on my cell, 713 304 8716. Thanks, Kay \"Keffer, John\" on 03/23/2001 :47 PM cc: \"Reuter, Marisa\" RE: ENA/Blue Dog: Revised Letter Agreement I failed to include the conference call information, which is noted below: number: 877-232-0064...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                   Tokenized_text  \\\n",
       "5131  Please forward to James Scribner. He will call with his e:mail address. = =20 ---------------------- Forwarded by Sally Beck/HOU/ECT on 01/25/2000 = AM=20 --------------------------- =20 =09Enron North America Corp. =09 =09 Rick Causey @ ENRON 01/17/2000 =09 Sent by: Enron All Enron Worldwide cc...   \n",
       "8996  Uh, YEAH! There's a WHOLE BUNCH of them! Single ones, squishy ones, firm ones...wanna feel 'em? =o) HA HA HA!!! -----Original Message----- Symes, Kate Wednesday, May 02, 2001 Rodriguez, Grace Re: EWWW TOMATOES! You have beef-cakes up there? Are they single? Grace on 05/02/2001 CDT Lysa Tom Rober...   \n",
       "4956  Thanks. -----Original Message----- Novosel, Sarah Thursday, October 25, 2001 Shapiro, Richard; Steffes, James D. Cc: Robertson, Linda FW: November 2 Seattle Conference I sent to Kevin the names forwarded to us from Paul for possible panelists from Western governors' offices for FERC's November 2...   \n",
       "1787  -----Original Message----- Stein, Neil [mailMonday, September 24, 2001 undisclosed-recipients CSFB Independent Power Weekly--Issue #44 <<IPW092401.pdf>> Good Morning, Attached, please find the latest issue of our Independent Power Weekly. Also note that there is a replay available of our confere...   \n",
       "1285  John or Marissa, please call me at your convenience on my cell, 713 304 8716. Thanks, Kay \"Keffer, John\" on 03/23/2001 :47 PM cc: \"Reuter, Marisa\" RE: ENA/Blue Dog: Revised Letter Agreement I failed to include the conference call information, which is noted below: number: 877-232-0064 pin: 25581...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    llama_summary  \n",
       "5131  summarize: Please forward to James Scribner. He will call with his e:mail address. = =20 ---------------------- Forwarded by Sally Beck/HOU/ECT on 01/25/2000 = AM=20 --------------------------- =20 =09Enron North America Corp. =09 =09 Rick Causey @ ENRON 01/17/2000 =09 Sent by: Enron All Enron W...  \n",
       "8996  summarize: Uh, YEAH! There's a WHOLE BUNCH of them! Single ones, squishy ones, firm ones...wanna feel 'em? =o) HA HA HA!!! -----Original Message----- Symes, Kate Wednesday, May 02, 2001 Rodriguez, Grace Re: EWWW TOMATOES! You have beef-cakes up there? Are they single? Grace on 05/02/2001 CDT Lys...  \n",
       "4956  summarize: Thanks. -----Original Message----- Novosel, Sarah Thursday, October 25, 2001 Shapiro, Richard; Steffes, James D. Cc: Robertson, Linda FW: November 2 Seattle Conference I sent to Kevin the names forwarded to us from Paul for possible panelists from Western governors' offices for FERC's...  \n",
       "1787  summarize: -----Original Message----- Stein, Neil [mailMonday, September 24, 2001 undisclosed-recipients CSFB Independent Power Weekly--Issue #44 <<IPW092401.pdf>> Good Morning, Attached, please find the latest issue of our Independent Power Weekly. Also note that there is a replay available of ...  \n",
       "1285  summarize: John or Marissa, please call me at your convenience on my cell, 713 304 8716. Thanks, Kay \"Keffer, John\" on 03/23/2001 :47 PM cc: \"Reuter, Marisa\" RE: ENA/Blue Dog: Revised Letter Agreement I failed to include the conference call information, which is noted below: number: 877-232-0064...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_email_thread(thread_text):\n",
    "    inputs = tokenizer(\"summarize: \" + thread_text, return_tensors=\"pt\",padding = True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length= max,\n",
    "        min_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Summarize the provided email thread\n",
    "data['llama_summary'] = data['Tokenized_text'].apply(summarize_email_thread)\n",
    "data[['Tokenized_text','llama_summary']].iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Status Update'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a zero-shot-classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model = 'facebook/bart-large-mnli',device=device)\n",
    "\n",
    "# Define classes for classification\n",
    "categories = [\"Meeting Request\", \"Status Update\", \"General Query\"]\n",
    "\n",
    "# Sample email content\n",
    "email_content = data.iloc[0]['Tokenized_text']\n",
    "\n",
    "# Classify the email\n",
    "result = classifier(\n",
    "    email_content,\n",
    "    candidate_labels=categories,\n",
    "    multi_label=False  # Set to True if you expect multiple relevant classes\n",
    ")\n",
    "\n",
    "result = {result['labels'][0]}\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "# # Response generation based on classification\n",
    "# responses = {\n",
    "#     \"Meeting Request\": \"Thank you for your meeting request. Please provide the agenda and your availability.\",\n",
    "#     \"Status Update\": \"Thank you for your update. Please let me know if there is any more information to be shared.\",\n",
    "#     \"General Query\": \"Thank you for reaching out. How can I assist you further?\"\n",
    "# }\n",
    "\n",
    "# response = responses.get(result['labels'][0], \"Thank you for your email.\")\n",
    "# print(f\"Generated Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generate a response mail to the following email based on the category Meeting Request Can we schedule a meeting tomorrow? Can we schedule a meeting this week? Can we schedule a meeting next week?\\nGenerate a response mail to the following email based on the category Meeting Request Can we schedule a meeting tomorrow? Can we schedule a meeting this week? Can we schedule a meeting next week?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"  \n",
    "# Load a pre-trained text generation model\n",
    "generator = pipeline('text-generation', model=model_name)\n",
    "\n",
    "def generate_response(email_content, prompt_prefix=f\"Generate a response mail to the following email based on the category {result['labels'][0]}\"):\n",
    "    prompt = f\"{prompt_prefix} {email_content}\"\n",
    "    responses = generator(prompt, max_length=max, num_return_sequences=1)\n",
    "    return responses[0]['generated_text']\n",
    "\n",
    "\n",
    "generate_response(email_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete.\n",
      "Classification result: {'Status Update'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832262878dd744bea74a7566d1f78433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9978e28481224185beedc1a0e73469bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5810c7e6967444ae9c5870f0cd256475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7880b10da4324b46955c8869379b7c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c11af44240404d9690ef71825c59c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fc568c06384f37a9c2fc6689fd2f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44cc8f02da04d049d2d0a2d6ff9253e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text generation...\n",
      "Text generation complete.\n",
      "{'generated_text': 'Generate a response mail to the following email in {\\'Status Update\\'} tone Hi Reavanth ,As discussed, Please find the assignment, which you need to complete in 2 days. Kindly complete and share it. :| Your Name, Email Address, and Reception Email Address: Hello? :| Your Phone Number, Number of Days, and Deceased Persons: (A) You: :| Your Title; (B) The Date in which you were Killed, Or Killed.\\n\\nDo you mean that the \"No Deaths After September 12 Incident\" rule is in place? :| It is not. :| We have yet to see the reply. :| What sort of response is still required to complete the assignment? I\\'d like to include my name, the names as well as the e-mail address. Thanks for your input. :|\\n\\n\\nDear Reavanth, I read the assignment with no further interest in contacting a government to retrieve a data file, so I wrote to your organization that is at that time collecting data on American citizen assassinations and has received no response to my call for assistance. When I inquired of you for help in investigating the deaths of this particular person from September 12, 1998, on your personal email, in which case I wrote to you with my statement in the form below. You have never received a reply to my question, and as far as I am aware, do not have any information about this case, including but not limited to a data file, in which case I have no further information but will not comment on your email or reply. I have learned that this was done by one of the \"New York City Police,\" which took to calling the U.S. Department of Justice and requesting the report of the missing persons from the Department of Justice. These statements may sound suspiciously like that of the two previous police chiefs for the NYPD, but this was not their original statement and this was done by another organization. Do you still remember seeing or know anything about the deaths of those men from this particular case, in the United States? :| The answer is no, but with respect to the FBI or the NYPD, I had no idea what occurred at the time. The case was dismissed. They now believe the murders may have been carried out by the same old person. I have no further contact information (I have not received any messages from the NYPD or FBI that relate to this ongoing investigation), and my name is being kept private until after my information is available'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from torch import cuda\n",
    "\n",
    "device = 0 if cuda.is_available() else -1\n",
    "\n",
    "# Load a zero-shot-classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model='facebook/bart-large-mnli', device=device,)\n",
    "\n",
    "# Define classes for classification\n",
    "categories = [\"Meeting Request\", \"Status Update\", \"General Query\"]\n",
    "\n",
    "# Sample email content (ensure it's defined and not too large)\n",
    "email_content = \"Hi Reavanth ,As discussed, Please find the assignment, which you need to complete in 2 days. Kindly complete and share it.\" # Truncate if necessary\n",
    "\n",
    "# Classify the email\n",
    "print(\"Starting classification...\")\n",
    "result = classifier(email_content, candidate_labels=categories, multi_label=False,truncation=False)\n",
    "print(\"Classification complete.\")\n",
    "result = {result['labels'][0]}\n",
    "print(\"Classification result:\", result)\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"  # Ensure this model exists\n",
    "generator = pipeline('text-generation', device=device,pad_token_id=generator.tokenizer.eos_token_id)\n",
    "\n",
    "prompt_prefix = f\"Generate a response mail to the following email in {result} tone\"\n",
    "prompt = f\"{prompt_prefix} {email_content}\"\n",
    "print(\"Starting text generation...\")\n",
    "responses = generator(prompt, max_length=513, num_return_sequences=1,truncation=True)  # Adjust max_length\n",
    "print(\"Text generation complete.\")\n",
    "print(responses[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f588658f15647c9b8e37bef0338bf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load pre-trained LLaMA model and tokenizer (example with LLaMA-2)\n",
    "model_name = \"Yihui/t5-small-text-summary-generation\"  # Specify the appropriate model path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Yihui/t5-small-text-summary-generation\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Yihui/t5-small-text-summary-generation\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Add padding token to tokenizer if it does not exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer)) # Resize model embeddings to accommodate the new padding token\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21603,    10,  2018,  8774,   149,    33,    25,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi Hi How are you? Hi Hi, how are you doing? Hi, Hi, How are You doing? Hello, Hello, how can you do it? Hi! Hi, I'm not a big fan of my blog!\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_email_thread(thread_text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\"summarize: \" + thread_text, return_tensors=\"pt\",padding = True)\n",
    "    print(inputs)\n",
    "    # inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Generate summary using model.generate()\n",
    "    summary_ids = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length= max,\n",
    "        min_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "prefi\n",
    "email = \"Hi Hello how are you\"\n",
    "summarize_email_thread(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
